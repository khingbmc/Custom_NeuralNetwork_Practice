{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "from random import randint\n",
    "import math\n",
    "from random import seed\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, inputs, hiddens, outputs):\n",
    "        print(inputs)\n",
    "        self.n_input = inputs\n",
    "        self.n_hidden = hiddens\n",
    "        self.n_output = outputs\n",
    "        self.network = []\n",
    "        hidden_layer = [{'weights':[random() for i in range(self.n_input)]} for i in range(self.n_hidden)] #random from num of inputlayer and hiddenlayer (input * hidden)\n",
    "        self.network.append(hidden_layer)\n",
    "        output_layer = [{'weights':[random() for i in range(self.n_hidden)]} for i in range(self.n_output)]\n",
    "        self.network.append(output_layer)\n",
    "        self.inputs = []\n",
    "        self.data = []\n",
    "        self.best_network = []\n",
    "        self.testing = []\n",
    "        \n",
    "    def compute_net_input(self, weight, inputs):\n",
    "        net_input = 0\n",
    "     \n",
    "        for i in range(len(weight)):\n",
    "            net_input += weight[i]*inputs[i]\n",
    "        return net_input\n",
    "\n",
    "    def sigmoid(self, net_input):\n",
    "        return 1.0/(1.0 + math.exp(-net_input))\n",
    "\n",
    "    def forward_propagate(self, data):\n",
    "        self.inputs = data\n",
    "        self.data = data\n",
    "        for layer in self.network:\n",
    "            next_inputs = []\n",
    "            for neuron in layer:\n",
    "                net_input = self.compute_net_input(neuron['weights'], self.inputs)\n",
    "                neuron['output'] = self.sigmoid(net_input)\n",
    "                next_inputs.append(neuron['output'])\n",
    "            self.inputs = next_inputs\n",
    "\n",
    "    #BackPropagation\n",
    "    def transfer_derivative(self, output):\n",
    "        return output * (1.0 - output)\n",
    "\n",
    "    def back_propagate(self, expected):\n",
    "        #backprop is begin in outputLayer\n",
    "        for i in reversed(range(len(self.network))):\n",
    "            layer = self.network[i]\n",
    "            errors = []\n",
    "            if i != len(self.network) - 1: #Hidden Layer\n",
    "                for j in range(len(layer)):\n",
    "                    error = 0.0\n",
    "                    for neuron in self.network[i + 1]:\n",
    "                        error += neuron['weights'][j] * neuron['errors']\n",
    "                    errors.append(error)\n",
    "            else:\n",
    "                for j in range(len(layer)):\n",
    "                    neuron = layer[j]\n",
    "                    errors.append(expected[j] - neuron['output'])\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                neuron['errors'] = errors[j] * self.transfer_derivative(neuron['output'])\n",
    "            \n",
    "    def update_weights(self, learn_rate):\n",
    "        for i in range(len(self.network)):\n",
    "            inputs = self.data[:-1]\n",
    "            # print(inputs)\n",
    "            if i != 0:\n",
    "                inputs = [neuron['output'] for neuron in self.network[i - 1]]\n",
    "            for neuron in self.network[i]:\n",
    "                for j in range(len(inputs)):\n",
    "                    neuron['weights'][j] += learn_rate * neuron['errors'] * inputs[j]\n",
    "                neuron['weights'][-1] += learn_rate * neuron['errors']\n",
    "\n",
    "    def training(self, dataset, learn_rate, num_iteration, num_output, tenflow_iterate):\n",
    "        number_testing = [35*tenflow_iterate, 21*tenflow_iterate] if tenflow_iterate != 9 else [7+(35*tenflow_iterate), 2+(21*tenflow_iterate)]\n",
    "        testing = [[x for x in range(number_testing[0])], [x for x in range(number_testing[1])]]\n",
    "        training = []\n",
    "        for i in range(num_output):\n",
    "#             for i in range(3):\n",
    "#                 testing.append(start_index+i)\n",
    "#                 testing.append(start_index+50+i)\n",
    "#                 testing.append(start_index+100+i)\n",
    "\n",
    "            for j in range(len(dataset[i])):\n",
    "                if j not in testing[i]:\n",
    "                    training.append(dataset[i][j])\n",
    "                else:\n",
    "                    self.testing.append(dataset[i][j])\n",
    "        \n",
    "        for iterate in range(num_iteration):\n",
    "            sum_error = 0\n",
    "            \n",
    "\n",
    "            for row in training:\n",
    "                self.forward_propagate(row)\n",
    "                expected = [0 for i in range(num_output)]\n",
    "                expected[row[-1]] = 1\n",
    "                # print(\"this is expect \", expected)\n",
    "\n",
    "                sum_error += sum([(expected[i] - self.inputs[i])**2 for i in range(len(expected))])\n",
    "                \n",
    "                self.back_propagate(expected)\n",
    "                self.update_weights(learn_rate)\n",
    "           \n",
    "            print('iteration=%d   learning_rate=%.4f   error=%.4f' % (iterate, learn_rate, sum_error))\n",
    "\n",
    "    def predict(self, row):\n",
    "        \n",
    "        self.forward_propagate(row)\n",
    "      \n",
    "        return self.inputs.index(max(self.inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define lambda function linear normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = lambda x, maxv, minv : (x-minv*0.95)/(maxv*1.05-minv*0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and set number of inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 2\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../wdbc.csv\", index_col=0)\n",
    "\n",
    "num = 0\n",
    "\n",
    "max_val, min_val = [0 for i in range(30)], [0 for i in range(30)]\n",
    "\n",
    "for i in data:\n",
    "    if(i != 'class'):\n",
    "        if(num == 30):\n",
    "            break\n",
    "        max_val[num] = max(data[i])\n",
    "        min_val[num] = min(data[i])\n",
    "        num += 1\n",
    "\n",
    "ID = data.index.values\n",
    "data_key = []\n",
    "for j in ID:\n",
    "    format_data = []\n",
    "    for i in data:\n",
    "        format_data.append(data[i][j])\n",
    "    data_key.append(format_data)\n",
    "\n",
    "\n",
    "num_inputs = len(data_key[0])-1 \n",
    "\n",
    "num_outputs = len(set(data['class']))\n",
    "print(num_inputs, num_outputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Input Layer:  30\n",
      "Number of Output Layer:  2\n",
      "[-0.30211742735522984, -0.2963777917220918, -0.26646598646863073, -0.054680412199359936, 0.3458016304686794, 0.7942636669532198, 5.288529063764034, 3.2168045761575144, 8.65001208552873, -0.31740895635803124, -0.05132739427726211, -0.07768026714785974, -0.03265962148612923, -0.0065571330030386255, 7.827695150142561, 5.704554277563616, 12.49826490590649, 7.273212575281293, 82.44550812936521, -7.999851901957228, -0.25770228736032064, -0.2867248979111518, -0.2220333667644048, -0.04102285904796219, -0.2665970332499976, 0.16632624122106818, 0.7329338036188305, -0.3614240783856547, -0.8470470099475637, -0.31577358125939836, 0]\n",
      "569 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_key)):\n",
    "    class_val = data_key[i][0]\n",
    "    del data_key[i][0]\n",
    "    data_key[i].append(1 if class_val == 'M' else 0)\n",
    "\n",
    "#tenflow 35 and 21 and last iteration is 42 and 23\n",
    "\n",
    "for i in range(len(data_key)):\n",
    "    for j in range(len(max_val)):\n",
    "        \n",
    "        data_key[i][j] = normalized(data_key[i][j], max_val[j], min_val[j])\n",
    "\n",
    "print(\"Number of Input Layer: \", num_inputs)\n",
    "print(\"Number of Output Layer: \", num_outputs)\n",
    "\n",
    "\n",
    "print(data_key[0])\n",
    "shuffle(data_key)\n",
    "input_data = [[] for _ in range(num_outputs)]\n",
    "for i in data_key:\n",
    "    if i[-1] == 0:\n",
    "        input_data[0].append(i)\n",
    "    else:\n",
    "        input_data[1].append(i)\n",
    "print(len(input_data[0]), len(input_data[1]))\n",
    "\n",
    "networks = []\n",
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "iteration=0   learning_rate=0.1000   error=124.8626\n",
      "iteration=1   learning_rate=0.1000   error=0.5293\n",
      "iteration=2   learning_rate=0.1000   error=0.3068\n",
      "iteration=3   learning_rate=0.1000   error=0.2223\n",
      "iteration=4   learning_rate=0.1000   error=0.1761\n",
      "iteration=5   learning_rate=0.1000   error=0.1464\n",
      "iteration=6   learning_rate=0.1000   error=0.1256\n",
      "iteration=7   learning_rate=0.1000   error=0.1101\n",
      "iteration=8   learning_rate=0.1000   error=0.0980\n",
      "iteration=9   learning_rate=0.1000   error=0.0884\n",
      "iteration=10   learning_rate=0.1000   error=0.0805\n",
      "iteration=11   learning_rate=0.1000   error=0.0740\n",
      "iteration=12   learning_rate=0.1000   error=0.0684\n",
      "iteration=13   learning_rate=0.1000   error=0.0636\n",
      "iteration=14   learning_rate=0.1000   error=0.0595\n",
      "iteration=15   learning_rate=0.1000   error=0.0558\n",
      "iteration=16   learning_rate=0.1000   error=0.0526\n",
      "iteration=17   learning_rate=0.1000   error=0.0498\n",
      "iteration=18   learning_rate=0.1000   error=0.0472\n",
      "iteration=19   learning_rate=0.1000   error=0.0449\n",
      "iteration=20   learning_rate=0.1000   error=0.0428\n",
      "iteration=21   learning_rate=0.1000   error=0.0409\n",
      "iteration=22   learning_rate=0.1000   error=0.0391\n",
      "iteration=23   learning_rate=0.1000   error=0.0375\n",
      "iteration=24   learning_rate=0.1000   error=0.0360\n",
      "iteration=25   learning_rate=0.1000   error=0.0347\n",
      "iteration=26   learning_rate=0.1000   error=0.0334\n",
      "iteration=27   learning_rate=0.1000   error=0.0322\n",
      "iteration=28   learning_rate=0.1000   error=0.0311\n",
      "iteration=29   learning_rate=0.1000   error=0.0301\n",
      "iteration=30   learning_rate=0.1000   error=0.0292\n",
      "iteration=31   learning_rate=0.1000   error=0.0283\n",
      "iteration=32   learning_rate=0.1000   error=0.0274\n",
      "iteration=33   learning_rate=0.1000   error=0.0266\n",
      "iteration=34   learning_rate=0.1000   error=0.0259\n",
      "iteration=35   learning_rate=0.1000   error=0.0251\n",
      "iteration=36   learning_rate=0.1000   error=0.0245\n",
      "iteration=37   learning_rate=0.1000   error=0.0238\n",
      "iteration=38   learning_rate=0.1000   error=0.0232\n",
      "iteration=39   learning_rate=0.1000   error=0.0227\n",
      "iteration=40   learning_rate=0.1000   error=0.0221\n",
      "iteration=41   learning_rate=0.1000   error=0.0216\n",
      "iteration=42   learning_rate=0.1000   error=0.0211\n",
      "iteration=43   learning_rate=0.1000   error=0.0206\n",
      "iteration=44   learning_rate=0.1000   error=0.0202\n",
      "iteration=45   learning_rate=0.1000   error=0.0197\n",
      "iteration=46   learning_rate=0.1000   error=0.0193\n",
      "iteration=47   learning_rate=0.1000   error=0.0189\n",
      "iteration=48   learning_rate=0.1000   error=0.0185\n",
      "iteration=49   learning_rate=0.1000   error=0.0182\n",
      "iteration=50   learning_rate=0.1000   error=0.0178\n",
      "iteration=51   learning_rate=0.1000   error=0.0175\n",
      "iteration=52   learning_rate=0.1000   error=0.0171\n",
      "iteration=53   learning_rate=0.1000   error=0.0168\n",
      "iteration=54   learning_rate=0.1000   error=0.0165\n",
      "iteration=55   learning_rate=0.1000   error=0.0162\n",
      "iteration=56   learning_rate=0.1000   error=0.0159\n",
      "iteration=57   learning_rate=0.1000   error=0.0157\n",
      "iteration=58   learning_rate=0.1000   error=0.0154\n",
      "iteration=59   learning_rate=0.1000   error=0.0152\n",
      "iteration=60   learning_rate=0.1000   error=0.0149\n",
      "iteration=61   learning_rate=0.1000   error=0.0147\n",
      "iteration=62   learning_rate=0.1000   error=0.0144\n",
      "iteration=63   learning_rate=0.1000   error=0.0142\n",
      "iteration=64   learning_rate=0.1000   error=0.0140\n",
      "iteration=65   learning_rate=0.1000   error=0.0138\n",
      "iteration=66   learning_rate=0.1000   error=0.0136\n",
      "iteration=67   learning_rate=0.1000   error=0.0134\n",
      "iteration=68   learning_rate=0.1000   error=0.0132\n",
      "iteration=69   learning_rate=0.1000   error=0.0130\n",
      "iteration=70   learning_rate=0.1000   error=0.0128\n",
      "iteration=71   learning_rate=0.1000   error=0.0126\n",
      "iteration=72   learning_rate=0.1000   error=0.0125\n",
      "iteration=73   learning_rate=0.1000   error=0.0123\n",
      "iteration=74   learning_rate=0.1000   error=0.0121\n",
      "iteration=75   learning_rate=0.1000   error=0.0120\n",
      "iteration=76   learning_rate=0.1000   error=0.0118\n",
      "iteration=77   learning_rate=0.1000   error=0.0117\n",
      "iteration=78   learning_rate=0.1000   error=0.0115\n",
      "iteration=79   learning_rate=0.1000   error=0.0114\n",
      "iteration=80   learning_rate=0.1000   error=0.0112\n",
      "iteration=81   learning_rate=0.1000   error=0.0111\n",
      "iteration=82   learning_rate=0.1000   error=0.0110\n",
      "iteration=83   learning_rate=0.1000   error=0.0108\n",
      "iteration=84   learning_rate=0.1000   error=0.0107\n",
      "iteration=85   learning_rate=0.1000   error=0.0106\n",
      "iteration=86   learning_rate=0.1000   error=0.0105\n",
      "iteration=87   learning_rate=0.1000   error=0.0104\n",
      "iteration=88   learning_rate=0.1000   error=0.0102\n",
      "iteration=89   learning_rate=0.1000   error=0.0101\n",
      "iteration=90   learning_rate=0.1000   error=0.0100\n",
      "iteration=91   learning_rate=0.1000   error=0.0099\n",
      "iteration=92   learning_rate=0.1000   error=0.0098\n",
      "iteration=93   learning_rate=0.1000   error=0.0097\n",
      "iteration=94   learning_rate=0.1000   error=0.0096\n",
      "iteration=95   learning_rate=0.1000   error=0.0095\n",
      "iteration=96   learning_rate=0.1000   error=0.0094\n",
      "iteration=97   learning_rate=0.1000   error=0.0093\n",
      "iteration=98   learning_rate=0.1000   error=0.0092\n",
      "iteration=99   learning_rate=0.1000   error=0.0091\n",
      "iteration=100   learning_rate=0.1000   error=0.0090\n",
      "iteration=101   learning_rate=0.1000   error=0.0089\n",
      "iteration=102   learning_rate=0.1000   error=0.0088\n",
      "iteration=103   learning_rate=0.1000   error=0.0088\n",
      "iteration=104   learning_rate=0.1000   error=0.0087\n",
      "iteration=105   learning_rate=0.1000   error=0.0086\n",
      "iteration=106   learning_rate=0.1000   error=0.0085\n",
      "iteration=107   learning_rate=0.1000   error=0.0084\n",
      "iteration=108   learning_rate=0.1000   error=0.0084\n",
      "iteration=109   learning_rate=0.1000   error=0.0083\n",
      "iteration=110   learning_rate=0.1000   error=0.0082\n",
      "iteration=111   learning_rate=0.1000   error=0.0081\n",
      "iteration=112   learning_rate=0.1000   error=0.0081\n",
      "iteration=113   learning_rate=0.1000   error=0.0080\n",
      "iteration=114   learning_rate=0.1000   error=0.0079\n",
      "iteration=115   learning_rate=0.1000   error=0.0079\n",
      "iteration=116   learning_rate=0.1000   error=0.0078\n",
      "iteration=117   learning_rate=0.1000   error=0.0077\n",
      "iteration=118   learning_rate=0.1000   error=0.0077\n",
      "iteration=119   learning_rate=0.1000   error=0.0076\n",
      "iteration=120   learning_rate=0.1000   error=0.0075\n",
      "iteration=121   learning_rate=0.1000   error=0.0075\n",
      "iteration=122   learning_rate=0.1000   error=0.0074\n",
      "iteration=123   learning_rate=0.1000   error=0.0074\n",
      "iteration=124   learning_rate=0.1000   error=0.0073\n",
      "iteration=125   learning_rate=0.1000   error=0.0072\n",
      "iteration=126   learning_rate=0.1000   error=0.0072\n",
      "iteration=127   learning_rate=0.1000   error=0.0071\n",
      "iteration=128   learning_rate=0.1000   error=0.0071\n",
      "iteration=129   learning_rate=0.1000   error=0.0070\n",
      "iteration=130   learning_rate=0.1000   error=0.0070\n",
      "iteration=131   learning_rate=0.1000   error=0.0069\n",
      "iteration=132   learning_rate=0.1000   error=0.0069\n",
      "iteration=133   learning_rate=0.1000   error=0.0068\n",
      "iteration=134   learning_rate=0.1000   error=0.0068\n",
      "iteration=135   learning_rate=0.1000   error=0.0067\n",
      "iteration=136   learning_rate=0.1000   error=0.0067\n",
      "iteration=137   learning_rate=0.1000   error=0.0066\n",
      "iteration=138   learning_rate=0.1000   error=0.0066\n",
      "iteration=139   learning_rate=0.1000   error=0.0065\n",
      "iteration=140   learning_rate=0.1000   error=0.0065\n",
      "iteration=141   learning_rate=0.1000   error=0.0064\n",
      "iteration=142   learning_rate=0.1000   error=0.0064\n",
      "iteration=143   learning_rate=0.1000   error=0.0063\n",
      "iteration=144   learning_rate=0.1000   error=0.0063\n",
      "iteration=145   learning_rate=0.1000   error=0.0062\n",
      "iteration=146   learning_rate=0.1000   error=0.0062\n",
      "iteration=147   learning_rate=0.1000   error=0.0062\n",
      "iteration=148   learning_rate=0.1000   error=0.0061\n",
      "iteration=149   learning_rate=0.1000   error=0.0061\n",
      "iteration=150   learning_rate=0.1000   error=0.0060\n",
      "iteration=151   learning_rate=0.1000   error=0.0060\n",
      "iteration=152   learning_rate=0.1000   error=0.0060\n",
      "iteration=153   learning_rate=0.1000   error=0.0059\n",
      "iteration=154   learning_rate=0.1000   error=0.0059\n",
      "iteration=155   learning_rate=0.1000   error=0.0058\n",
      "iteration=156   learning_rate=0.1000   error=0.0058\n",
      "iteration=157   learning_rate=0.1000   error=0.0058\n",
      "iteration=158   learning_rate=0.1000   error=0.0057\n",
      "iteration=159   learning_rate=0.1000   error=0.0057\n",
      "iteration=160   learning_rate=0.1000   error=0.0057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=161   learning_rate=0.1000   error=0.0056\n",
      "iteration=162   learning_rate=0.1000   error=0.0056\n",
      "iteration=163   learning_rate=0.1000   error=0.0056\n",
      "iteration=164   learning_rate=0.1000   error=0.0055\n",
      "iteration=165   learning_rate=0.1000   error=0.0055\n",
      "iteration=166   learning_rate=0.1000   error=0.0055\n",
      "iteration=167   learning_rate=0.1000   error=0.0054\n",
      "iteration=168   learning_rate=0.1000   error=0.0054\n",
      "iteration=169   learning_rate=0.1000   error=0.0054\n",
      "iteration=170   learning_rate=0.1000   error=0.0053\n",
      "iteration=171   learning_rate=0.1000   error=0.0053\n",
      "iteration=172   learning_rate=0.1000   error=0.0053\n",
      "iteration=173   learning_rate=0.1000   error=0.0052\n",
      "iteration=174   learning_rate=0.1000   error=0.0052\n",
      "iteration=175   learning_rate=0.1000   error=0.0052\n",
      "iteration=176   learning_rate=0.1000   error=0.0052\n",
      "iteration=177   learning_rate=0.1000   error=0.0051\n",
      "iteration=178   learning_rate=0.1000   error=0.0051\n",
      "iteration=179   learning_rate=0.1000   error=0.0051\n",
      "iteration=180   learning_rate=0.1000   error=0.0050\n",
      "iteration=181   learning_rate=0.1000   error=0.0050\n",
      "iteration=182   learning_rate=0.1000   error=0.0050\n",
      "iteration=183   learning_rate=0.1000   error=0.0050\n",
      "iteration=184   learning_rate=0.1000   error=0.0049\n",
      "iteration=185   learning_rate=0.1000   error=0.0049\n",
      "iteration=186   learning_rate=0.1000   error=0.0049\n",
      "iteration=187   learning_rate=0.1000   error=0.0049\n",
      "iteration=188   learning_rate=0.1000   error=0.0048\n",
      "iteration=189   learning_rate=0.1000   error=0.0048\n",
      "iteration=190   learning_rate=0.1000   error=0.0048\n",
      "iteration=191   learning_rate=0.1000   error=0.0048\n",
      "iteration=192   learning_rate=0.1000   error=0.0047\n",
      "iteration=193   learning_rate=0.1000   error=0.0047\n",
      "iteration=194   learning_rate=0.1000   error=0.0047\n",
      "iteration=195   learning_rate=0.1000   error=0.0047\n",
      "iteration=196   learning_rate=0.1000   error=0.0046\n",
      "iteration=197   learning_rate=0.1000   error=0.0046\n",
      "iteration=198   learning_rate=0.1000   error=0.0046\n",
      "iteration=199   learning_rate=0.1000   error=0.0046\n",
      "iteration=200   learning_rate=0.1000   error=0.0045\n",
      "iteration=201   learning_rate=0.1000   error=0.0045\n",
      "iteration=202   learning_rate=0.1000   error=0.0045\n",
      "iteration=203   learning_rate=0.1000   error=0.0045\n",
      "iteration=204   learning_rate=0.1000   error=0.0045\n",
      "iteration=205   learning_rate=0.1000   error=0.0044\n",
      "iteration=206   learning_rate=0.1000   error=0.0044\n",
      "iteration=207   learning_rate=0.1000   error=0.0044\n",
      "iteration=208   learning_rate=0.1000   error=0.0044\n",
      "iteration=209   learning_rate=0.1000   error=0.0043\n",
      "iteration=210   learning_rate=0.1000   error=0.0043\n",
      "iteration=211   learning_rate=0.1000   error=0.0043\n",
      "iteration=212   learning_rate=0.1000   error=0.0043\n",
      "iteration=213   learning_rate=0.1000   error=0.0043\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-797f40bb6c33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnetworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnetworks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-4c72382883dd>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, dataset, learn_rate, num_iteration, num_output, tenflow_iterate)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexpected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-4c72382883dd>\u001b[0m in \u001b[0;36mforward_propagate\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mnext_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mnet_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_net_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mneuron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mnext_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-4c72382883dd>\u001b[0m in \u001b[0;36mcompute_net_input\u001b[0;34m(self, weight, inputs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mnet_input\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnet_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    networks.append(NeuralNetwork(num_inputs, 10, num_outputs))\n",
    "    networks[i].training(input_data, 0.1, 500, num_outputs, i)\n",
    "    \n",
    "    num = 0\n",
    "    for row in networks[i].testing:\n",
    "        prediction = networks[i].predict(row)\n",
    "        if row[-1] == prediction:\n",
    "            num += 1\n",
    "        print(\"Expect=%d  Output=%d\" % (row[-1], prediction))\n",
    "    accuracy.append(num/15*100)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Model \", i)\n",
    "    print(networks[i].network, end='\\n\\n')\n",
    "    print(\"Accuracy : \", accuracy[i])\n",
    "\n",
    "print(\"Mean Accuracy: \" ,sum(accuracy)/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
