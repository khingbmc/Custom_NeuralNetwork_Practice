{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "from random import randint\n",
    "import math\n",
    "from random import seed\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, inputs, hiddens, outputs):\n",
    "        print(inputs)\n",
    "        self.n_input = inputs\n",
    "        self.n_hidden = hiddens\n",
    "        self.n_output = outputs\n",
    "        self.network = []\n",
    "        hidden_layer = [{'weights':[random() for i in range(self.n_input)]} for i in range(self.n_hidden)] #random from num of inputlayer and hiddenlayer (input * hidden)\n",
    "        self.network.append(hidden_layer)\n",
    "        output_layer = [{'weights':[random() for i in range(self.n_hidden)]} for i in range(self.n_output)]\n",
    "        self.network.append(output_layer)\n",
    "        self.inputs = []\n",
    "        self.data = []\n",
    "        self.best_network = []\n",
    "        self.testing = []\n",
    "        \n",
    "    def compute_net_input(self, weight, inputs):\n",
    "        net_input = 0\n",
    "     \n",
    "        for i in range(len(weight)):\n",
    "            net_input += weight[i]*inputs[i]\n",
    "        return net_input\n",
    "\n",
    "    def sigmoid(self, net_input):\n",
    "        return 1.0/(1.0 + math.exp(-net_input))\n",
    "\n",
    "    def forward_propagate(self, data):\n",
    "        self.inputs = data\n",
    "        self.data = data\n",
    "        for layer in self.network:\n",
    "            next_inputs = []\n",
    "            for neuron in layer:\n",
    "                net_input = self.compute_net_input(neuron['weights'], self.inputs)\n",
    "                neuron['output'] = self.sigmoid(net_input)\n",
    "                next_inputs.append(neuron['output'])\n",
    "            self.inputs = next_inputs\n",
    "\n",
    "    #BackPropagation\n",
    "    def transfer_derivative(self, output):\n",
    "        return output * (1.0 - output)\n",
    "\n",
    "    def back_propagate(self, expected):\n",
    "        #backprop is begin in outputLayer\n",
    "        for i in reversed(range(len(self.network))):\n",
    "            layer = self.network[i]\n",
    "            errors = []\n",
    "            if i != len(self.network) - 1: #Hidden Layer\n",
    "                for j in range(len(layer)):\n",
    "                    error = 0.0\n",
    "                    for neuron in self.network[i + 1]:\n",
    "                        error += neuron['weights'][j] * neuron['errors']\n",
    "                    errors.append(error)\n",
    "            else:\n",
    "                for j in range(len(layer)):\n",
    "                    neuron = layer[j]\n",
    "                    errors.append(expected[j] - neuron['output'])\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                neuron['errors'] = errors[j] * self.transfer_derivative(neuron['output'])\n",
    "            \n",
    "    def update_weights(self, learn_rate):\n",
    "        for i in range(len(self.network)):\n",
    "            inputs = self.data[:-1]\n",
    "            # print(inputs)\n",
    "            if i != 0:\n",
    "                inputs = [neuron['output'] for neuron in self.network[i - 1]]\n",
    "            for neuron in self.network[i]:\n",
    "                for j in range(len(inputs)):\n",
    "                    neuron['weights'][j] += learn_rate * neuron['errors'] * inputs[j]\n",
    "                neuron['weights'][-1] += learn_rate * neuron['errors']\n",
    "\n",
    "    def training(self, dataset, learn_rate, num_iteration, num_output, start_index):\n",
    "        number_testing = [35*tenflow_iterate, 21*tenflow_iterate] if tenflow_iterate != 9 else [7+(35*tenflow_iterate), 2+(21*tenflow_iterate)]\n",
    "        testing = [[x for x in range(number_testing[0])], [x for x in range(number_testing[1])]]\n",
    "        training = []\n",
    "        for i in range(num_output):\n",
    "#             for i in range(3):\n",
    "#                 testing.append(start_index+i)\n",
    "#                 testing.append(start_index+50+i)\n",
    "#                 testing.append(start_index+100+i)\n",
    "\n",
    "            for j in range(len(dataset[i])):\n",
    "                if j not in testing[i]:\n",
    "                    training.append(dataset[i][j])\n",
    "                else:\n",
    "                    self.testing.append(dataset[i][j])\n",
    "        \n",
    "        for iterate in range(num_iteration):\n",
    "            sum_error = 0\n",
    "            \n",
    "\n",
    "            for row in training:\n",
    "                self.forward_propagate(row)\n",
    "                expected = [0 for i in range(num_output)]\n",
    "                expected[row[-1]] = 1\n",
    "                # print(\"this is expect \", expected)\n",
    "\n",
    "                sum_error += sum([(expected[i] - self.inputs[i])**2 for i in range(len(expected))])\n",
    "                \n",
    "                self.back_propagate(expected)\n",
    "                self.update_weights(learn_rate)\n",
    "           \n",
    "            print('iteration=%d   learning_rate=%.4f   error=%.4f' % (iterate, learn_rate, sum_error))\n",
    "\n",
    "    def predict(self, row):\n",
    "        \n",
    "        self.forward_propagate(row)\n",
    "      \n",
    "        return self.inputs.index(max(self.inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define lambda function linear normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = lambda x, maxv, minv : (x-minv*0.95)/(maxv*1.05-minv*0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and set number of inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../wdbc.csv\", index_col=0)\n",
    "\n",
    "num = 0\n",
    "\n",
    "max_val, min_val = [0 for i in range(30)], [0 for i in range(30)]\n",
    "\n",
    "for i in data:\n",
    "    if(i != 'class'):\n",
    "        if(num == 30):\n",
    "            break\n",
    "        max_val[num] = max(data[i])\n",
    "        min_val[num] = min(data[i])\n",
    "        num += 1\n",
    "\n",
    "ID = data.index.values\n",
    "data_key = []\n",
    "for j in ID:\n",
    "    format_data = []\n",
    "    for i in data:\n",
    "        format_data.append(data[i][j])\n",
    "    data_key.append(format_data)\n",
    "\n",
    "\n",
    "num_inputs = len(data_key[0])-1 \n",
    "print(num_inputs)\n",
    "num_outputs = len(set(data['class']))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Input Layer:  30\n",
      "Number of Output Layer:  2\n",
      "[0.49634125824008946, 0.036087384250222516, 0.5194291361878657, 0.3472973922822801, 0.562644205261924, 0.7528895395617835, 0.6696568036774221, 0.6962984000757361, 0.6462242562929063, 0.5696991795806746, 0.3398036571644521, 0.11763169878798259, 0.35196345234874116, 0.26106173228620655, 0.1536310555826544, 0.3349310793497993, 0.12922077922077918, 0.2863096365653668, 0.2989287836031487, 0.1752821506767614, 0.5888282165069205, 0.14559830533523815, 0.6332986674881468, 0.429541619666446, 0.5694037689962286, 0.58957560753732, 0.5415335463258786, 0.868597610865652, 0.5679673180562268, 0.40227795660287347, 1]\n",
      "357 212\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_key)):\n",
    "    class_val = data_key[i][0]\n",
    "    del data_key[i][0]\n",
    "    data_key[i].append(1 if class_val == 'M' else 0)\n",
    "\n",
    "#tenflow 35 and 21 and last iteration is 42 and 23\n",
    "\n",
    "for i in range(len(data_key)):\n",
    "    for j in range(len(max_val)):\n",
    "        \n",
    "        data_key[i][j] = normalized(data_key[i][j], max_val[j], min_val[j])\n",
    "\n",
    "print(\"Number of Input Layer: \", num_inputs)\n",
    "print(\"Number of Output Layer: \", num_outputs)\n",
    "\n",
    "\n",
    "print(data_key[0])\n",
    "shuffle(data_key)\n",
    "input_data = [[] for _ in range(num_outputs)]\n",
    "for i in data_key:\n",
    "    if i[-1] == 0:\n",
    "        input_data[0].append(i)\n",
    "    else:\n",
    "        input_data[1].append(i)\n",
    "print(len(input_data[0]), len(input_data[1]))\n",
    "\n",
    "networks = []\n",
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-797f40bb6c33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnetworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnetworks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-470f59590a7c>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, dataset, learn_rate, num_output, tenflow_iterate, start_index)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m#                 testing.append(start_index+100+i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    networks.append(NeuralNetwork(num_inputs, 10, num_outputs))\n",
    "    networks[i].training(input_data, 0.1, 500, num_outputs, i)\n",
    "    \n",
    "    num = 0\n",
    "    for row in networks[i].testing:\n",
    "        prediction = networks[i].predict(row)\n",
    "        if row[-1] == prediction:\n",
    "            num += 1\n",
    "        print(\"Expect=%d  Output=%d\" % (row[-1], prediction))\n",
    "    accuracy.append(num/15*100)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Model \", i)\n",
    "    print(networks[i].network, end='\\n\\n')\n",
    "    print(\"Accuracy : \", accuracy[i])\n",
    "\n",
    "print(\"Mean Accuracy: \" ,sum(accuracy)/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
